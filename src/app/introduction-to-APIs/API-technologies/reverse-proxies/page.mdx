import BackToTop from "@/components/BackToTop";

# Reverse Proxies

## Table of Contents

## Overview

Reverse proxies are intermediary servers that act as gateways between clients and backend servers, forwarding client requests to appropriate backend services and returning responses back to clients. Unlike forward proxies that serve clients by hiding their identity from servers, reverse proxies serve servers by hiding server complexity from clients.

In modern distributed architectures, reverse proxies are essential infrastructure components that provide load balancing, SSL termination, caching, security, and routing capabilities. They enable horizontal scaling, improve performance, and add an abstraction layer that simplifies client-server interactions.

## How Reverse Proxies Work

```
[Client] → [Reverse Proxy] → [Backend Server 1]
                         → [Backend Server 2]
                         → [Backend Server 3]
```

### Request Flow:

1. **Client Request**: Client sends HTTP/HTTPS request to reverse proxy
2. **Request Processing**: Proxy analyzes request headers, path, and content
3. **Backend Selection**: Proxy selects appropriate backend server based on load balancing algorithm
4. **Request Forwarding**: Proxy forwards modified request to selected backend
5. **Response Processing**: Backend processes request and sends response to proxy
6. **Response Modification**: Proxy may modify response (caching, compression, headers)
7. **Client Response**: Proxy returns final response to client

### Comparison with Forward Proxies

| Aspect            | Forward Proxy                          | Reverse Proxy                        |
| ----------------- | -------------------------------------- | ------------------------------------ |
| **Purpose**       | Hides client identity from servers     | Hides server complexity from clients |
| **Position**      | Between client and internet            | Between internet and servers         |
| **Configuration** | Configured on client side              | Configured on server side            |
| **Use Case**      | Corporate firewalls, content filtering | Load balancing, SSL termination      |

## Key Features

- **Load Balancing**: Distributes incoming requests across multiple backend servers using various algorithms:

  - **Round Robin**: Requests distributed sequentially across servers
  - **Least Connections**: Routes to server with fewest active connections
  - **IP Hash**: Routes based on client IP hash for session persistence
  - **Weighted**: Assigns different weights to servers based on capacity
  - **Health-based**: Routes only to healthy servers based on health checks

- **SSL/TLS Termination**: Handles SSL encryption/decryption to offload cryptographic processing from backend servers:

  - **Certificate Management**: Centralized SSL certificate storage and renewal
  - **Protocol Support**: TLS 1.2/1.3, HTTP/2, HTTP/3 support
  - **Cipher Suite Management**: Control over encryption algorithms and security settings

- **Caching**: Stores frequently requested content to improve response times:

  - **Static Content Caching**: Images, CSS, JavaScript files
  - **Dynamic Content Caching**: API responses, rendered pages
  - **Cache Invalidation**: TTL-based or manual cache clearing
  - **Cache Headers**: Proper cache control header management

- **Request/Response Modification**:

  - **Header Manipulation**: Add, remove, or modify HTTP headers
  - **URL Rewriting**: Transform URLs before forwarding to backends
  - **Content Compression**: Gzip, Brotli compression for bandwidth optimization
  - **Request Routing**: Route based on URL patterns, headers, or query parameters

- **Security Features**:

  - **DDoS Protection**: Rate limiting and traffic filtering
  - **Web Application Firewall (WAF)**: SQL injection, XSS protection
  - **IP Whitelisting/Blacklisting**: Access control based on client IP
  - **Request Size Limiting**: Prevent oversized request attacks

- **Health Monitoring**:
  - **Health Checks**: Periodic checks to backend server availability
  - **Failover**: Automatic routing away from failed servers
  - **Circuit Breaker**: Temporary isolation of problematic backends
  - **Graceful Degradation**: Fallback responses when backends are unavailable
    <BackToTop />

## Configuration Examples

### Basic Nginx Reverse Proxy

```nginx
# /etc/nginx/sites-available/reverse-proxy
upstream backend_servers {
    # Load balancing configuration
    least_conn;  # Use least connections algorithm

    server backend1.example.com:8080 weight=3;
    server backend2.example.com:8080 weight=2;
    server backend3.example.com:8080 weight=1 backup;  # Backup server

    # Health checks (Nginx Plus feature)
    # health_check interval=5s fails=3 passes=2;
}

server {
    listen 80;
    listen 443 ssl http2;
    server_name api.example.com;

    # SSL Configuration
    ssl_certificate /etc/ssl/certs/example.com.crt;
    ssl_certificate_key /etc/ssl/private/example.com.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;

    # Security Headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

    # Rate Limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req zone=api burst=20 nodelay;

    # Logging
    access_log /var/log/nginx/api_access.log;
    error_log /var/log/nginx/api_error.log;

    # Proxy Configuration
    location / {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;

        # Buffer settings
        proxy_buffering on;
        proxy_buffer_size 128k;
        proxy_buffers 4 256k;
        proxy_busy_buffers_size 256k;

        # Error handling
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
    }

    # Static content caching
    location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
        proxy_pass http://backend_servers;
        proxy_cache_valid 200 1h;
        proxy_cache_key $uri$is_args$args;
        add_header X-Cache-Status $upstream_cache_status;
        expires 1h;
    }

    # API versioning
    location /v1/ {
        proxy_pass http://backend_servers/api/v1/;
        proxy_set_header API-Version "1.0";
    }

    location /v2/ {
        proxy_pass http://backend_servers/api/v2/;
        proxy_set_header API-Version "2.0";
    }

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

<BackToTop />

### HAProxy Configuration

```haproxy
# /etc/haproxy/haproxy.cfg
global
    daemon
    user haproxy
    group haproxy
    chroot /var/lib/haproxy

    # SSL Configuration
    ssl-default-bind-ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384
    ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

    # Logging
    log stdout local0 info

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms
    option httplog
    option dontlognull
    retries 3

    # Health checks
    option httpchk GET /health
    http-check expect status 200

# Frontend configuration
frontend web_frontend
    bind *:80
    bind *:443 ssl crt /etc/ssl/certs/example.com.pem

    # Redirect HTTP to HTTPS
    redirect scheme https if !{ ssl_fc }

    # Rate limiting
    stick-table type ip size 100k expire 30s store http_req_rate(10s)
    http-request track-sc0 src
    http-request deny if { sc_http_req_rate(0) gt 20 }

    # Security headers
    http-response set-header X-Frame-Options DENY
    http-response set-header X-Content-Type-Options nosniff
    http-response set-header Strict-Transport-Security "max-age=31536000; includeSubDomains"

    # Route based on path
    acl is_api path_beg /api/
    acl is_static path_beg /static/
    acl is_admin path_beg /admin/

    use_backend api_servers if is_api
    use_backend static_servers if is_static
    use_backend admin_servers if is_admin
    default_backend web_servers

# Backend configurations
backend web_servers
    balance roundrobin

    # Health checks
    option httpchk GET /health HTTP/1.1\r\nHost:\ example.com

    server web1 192.168.1.10:8080 check weight 100
    server web2 192.168.1.11:8080 check weight 100
    server web3 192.168.1.12:8080 check weight 50 backup

backend api_servers
    balance leastconn

    # Sticky sessions for API
    cookie SERVERID insert indirect nocache

    server api1 192.168.1.20:3000 check cookie api1
    server api2 192.168.1.21:3000 check cookie api2
    server api3 192.168.1.22:3000 check cookie api3

backend static_servers
    balance roundrobin

    # Long timeout for file uploads
    timeout server 5m

    server static1 192.168.1.30:8080 check
    server static2 192.168.1.31:8080 check

backend admin_servers
    balance roundrobin

    # IP whitelist for admin access
    acl allowed_ips src 10.0.0.0/8 192.168.0.0/16
    http-request deny unless allowed_ips

    server admin1 192.168.1.40:9000 check

# Statistics interface
listen stats
    bind *:8404
    stats enable
    stats uri /stats
    stats refresh 30s
    stats admin if { src 192.168.1.0/24 }
```

<BackToTop />

### Traefik Configuration (Docker Compose)

```yaml
# docker-compose.yml
version: "3.8"

services:
  traefik:
    image: traefik:v2.10
    container_name: traefik
    command:
      # API and dashboard
      - "--api.dashboard=true"
      - "--api.insecure=false"

      # Entry points
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"

      # Certificate resolver for Let's Encrypt
      - "--certificatesresolvers.letsencrypt.acme.tlschallenge=true"
      - "--certificatesresolvers.letsencrypt.acme.email=admin@example.com"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"

      # Docker provider
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"

      # Logging
      - "--log.level=INFO"
      - "--accesslog=true"

      # Metrics
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.addEntryPointsLabels=true"

    ports:
      - "80:80"
      - "443:443"
      - "8080:8080" # Dashboard

    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./letsencrypt:/letsencrypt

    networks:
      - traefik-network

    labels:
      # Dashboard
      - "traefik.enable=true"
      - "traefik.http.routers.dashboard.rule=Host(`traefik.example.com`)"
      - "traefik.http.routers.dashboard.tls.certresolver=letsencrypt"
      - "traefik.http.routers.dashboard.service=api@internal"
      - "traefik.http.routers.dashboard.middlewares=auth"

      # Basic auth middleware
      - "traefik.http.middlewares.auth.basicauth.users=admin:$$2y$$10$$..."

      # Global redirect to HTTPS
      - "traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)"
      - "traefik.http.routers.http-catchall.entrypoints=web"
      - "traefik.http.routers.http-catchall.middlewares=redirect-to-https"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"

  # Backend services
  web-app:
    image: nginx:alpine
    container_name: web-app
    networks:
      - traefik-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.web-app.rule=Host(`app.example.com`)"
      - "traefik.http.routers.web-app.entrypoints=websecure"
      - "traefik.http.routers.web-app.tls.certresolver=letsencrypt"
      - "traefik.http.services.web-app.loadbalancer.server.port=80"

      # Rate limiting
      - "traefik.http.middlewares.ratelimit.ratelimit.burst=100"
      - "traefik.http.middlewares.ratelimit.ratelimit.average=50"
      - "traefik.http.routers.web-app.middlewares=ratelimit"

  api-service:
    image: node:alpine
    container_name: api-service
    networks:
      - traefik-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.api.rule=Host(`api.example.com`) && PathPrefix(`/api/`)"
      - "traefik.http.routers.api.entrypoints=websecure"
      - "traefik.http.routers.api.tls.certresolver=letsencrypt"
      - "traefik.http.services.api.loadbalancer.server.port=3000"

      # CORS middleware
      - "traefik.http.middlewares.cors.headers.accesscontrolallowmethods=GET,OPTIONS,PUT,POST,DELETE"
      - "traefik.http.middlewares.cors.headers.accesscontrolalloworigin=*"
      - "traefik.http.middlewares.cors.headers.accesscontrolmaxage=100"
      - "traefik.http.middlewares.cors.headers.addvaryheader=true"
      - "traefik.http.routers.api.middlewares=cors"

networks:
  traefik-network:
    external: true
```

<BackToTop />

### Caddy Configuration

```caddyfile
# Caddyfile
{
    # Global options
    email admin@example.com

    # Logging
    log {
        output file /var/log/caddy/access.log
        format json
    }
}

# Main application
app.example.com {
    # Rate limiting
    rate_limit {
        zone static_ip
        key {remote_host}
        events 100
        window 1m
    }

    # Security headers
    header {
        X-Frame-Options DENY
        X-Content-Type-Options nosniff
        X-XSS-Protection "1; mode=block"
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        -Server  # Remove server header
    }

    # Load balancing
    reverse_proxy /api/* {
        to http://backend1:3000 http://backend2:3000 http://backend3:3000
        lb_policy least_conn

        # Health checks
        health_uri /health
        health_interval 30s
        health_timeout 5s

        # Headers
        header_up Host {upstream_hostport}
        header_up X-Real-IP {remote_host}
        header_up X-Forwarded-For {remote_host}
        header_up X-Forwarded-Proto {scheme}
    }

    # Static file serving with caching
    handle /static/* {
        file_server
        header Cache-Control "public, max-age=31536000"
    }

    # Default to main application
    reverse_proxy {
        to http://web-server:8080
        header_up Host {upstream_hostport}
        header_up X-Real-IP {remote_host}
    }
}

# API subdomain
api.example.com {
    # CORS
    @cors_preflight method OPTIONS
    handle @cors_preflight {
        header Access-Control-Allow-Origin "*"
        header Access-Control-Allow-Methods "GET, POST, PUT, PATCH, DELETE, OPTIONS"
        header Access-Control-Allow-Headers "Content-Type, Authorization"
        header Access-Control-Max-Age "86400"
        respond "" 204
    }

    # API versioning
    handle /v1/* {
        reverse_proxy http://api-v1:3001 {
            header_up API-Version "1.0"
        }
    }

    handle /v2/* {
        reverse_proxy http://api-v2:3002 {
            header_up API-Version "2.0"
        }
    }

    # Default API handler
    reverse_proxy http://api-latest:3000

    # Add CORS headers to all responses
    header Access-Control-Allow-Origin "*"
}

# Admin panel with IP restriction
admin.example.com {
    # IP whitelist
    @allowed remote_ip 10.0.0.0/8 192.168.0.0/16

    handle @allowed {
        reverse_proxy http://admin-panel:9000
    }

    handle {
        respond "Access Denied" 403
    }
}
```

<BackToTop />

### Use Cases

- **High-Traffic Web Applications**:

  - **Load Distribution**: Handle millions of requests across multiple servers
  - **Session Persistence**: Maintain user sessions across server restarts
  - **Auto-scaling**: Dynamic backend server provisioning based on traffic
  - **Global Load Balancing**: Route users to nearest data center

- **Microservices Architecture**:

  - **Service Discovery**: Automatic routing to available service instances
  - **Circuit Breaking**: Prevent cascading failures between services
  - **Request Routing**: Route based on service version, user type, or A/B testing
  - **Protocol Translation**: Convert between HTTP/1.1, HTTP/2, and gRPC

- **API Gateways**:

  - **Authentication/Authorization**: Centralized security policy enforcement
  - **Rate Limiting**: Prevent API abuse and ensure fair usage
  - **Request/Response Transformation**: Data format conversion and validation
  - **Analytics**: Request tracking, monitoring, and business intelligence

- **Content Delivery and CDN**:

  - **Edge Caching**: Cache static content at edge locations
  - **Image Optimization**: Dynamic image resizing and format conversion
  - **Bandwidth Optimization**: Content compression and minification
  - **Origin Shield**: Protect origin servers from direct requests

- **Legacy System Integration**:
  - **Protocol Bridging**: Connect modern clients to legacy backends
  - **API Modernization**: Add REST APIs to legacy SOAP services
  - **Gradual Migration**: Slowly migrate traffic from old to new systems
  - **Compatibility Layer**: Handle different API versions simultaneously

### Benefits

- **Performance Optimization**:

  - **Reduced Latency**: Caching frequently requested content locally
  - **Connection Pooling**: Reuse connections to backend servers
  - **Content Compression**: Reduce bandwidth usage with gzip/brotli
  - **HTTP/2 Multiplexing**: Handle multiple requests over single connection

- **Scalability and Reliability**:

  - **Horizontal Scaling**: Add backend servers without client changes
  - **High Availability**: Automatic failover to healthy servers
  - **Load Distribution**: Prevent any single server from being overwhelmed
  - **Graceful Degradation**: Serve cached content when backends are down

- **Security Enhancements**:

  - **DDoS Mitigation**: Rate limiting and traffic filtering
  - **SSL/TLS Termination**: Centralized certificate management
  - **Attack Surface Reduction**: Hide backend server details from clients
  - **Web Application Firewall**: Filter malicious requests before they reach backends

- **Operational Simplification**:
  - **Centralized Configuration**: Single point for routing and security rules
  - **Monitoring**: Unified logging and metrics collection
  - **Blue-Green Deployments**: Zero-downtime application updates
  - **Cost Optimization**: Efficient resource utilization and auto-scaling
    <BackToTop />

### Challenges

- **Configuration Complexity**:

  - **Learning Curve**: Each proxy solution has different configuration syntax
  - **Rule Management**: Complex routing rules can become difficult to maintain
  - **Testing**: Validating proxy configurations in development environments
  - **Documentation**: Keeping configuration documentation up-to-date

- **Performance Considerations**:

  - **Additional Latency**: Every hop adds network latency
  - **Resource Overhead**: Proxy servers consume CPU, memory, and bandwidth
  - **Bottleneck Risk**: Proxy can become performance bottleneck if not properly scaled
  - **Cache Invalidation**: Stale cached content can serve outdated information

- **Operational Challenges**:

  - **Single Point of Failure**: Proxy failure affects all backend services
  - **Debugging Complexity**: Tracing requests through multiple proxy layers
  - **Health Check Configuration**: Properly configuring backend health monitoring
  - **Log Management**: Aggregating and analyzing logs from multiple sources

- **Security Risks**:
  - **Proxy Vulnerabilities**: Security flaws in proxy software can expose entire infrastructure
  - **Configuration Errors**: Misconfigured rules can expose sensitive endpoints
  - **Certificate Management**: SSL certificate renewal and distribution
  - **Access Control**: Ensuring proper authentication and authorization
    <BackToTop />

## Popular Reverse Proxy Solutions

| Provider                                                                          | Description                                                                                                                                         | Key Features                                                                                                | Best For                                                             |
| --------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| [**Nginx**](https://www.nginx.com/)                                               | High-performance web server and reverse proxy known for handling high concurrency with low resource usage. Used by Netflix, Dropbox, and Pinterest. | Event-driven architecture, HTTP/2 support, advanced caching, SSL termination, WebSocket proxying            | High-traffic websites, static content serving, microservices         |
| [**HAProxy**](https://www.haproxy.org/)                                           | Reliable, high-performance TCP/HTTP load balancer used by GitHub, Reddit, and Stack Overflow. Known for advanced load balancing algorithms.         | Layer 4/7 load balancing, advanced health checks, SSL termination, ACL-based routing, real-time statistics  | Load balancing, high availability, enterprise applications           |
| [**Apache Traffic Server**](https://trafficserver.apache.org/)                    | Enterprise-grade caching proxy originally developed by Yahoo, now used by major CDN providers.                                                      | Massive caching capabilities, plugin architecture, ESI support, hierarchical caching                        | CDN, large-scale caching, high-throughput scenarios                  |
| [**Caddy**](https://caddyserver.com/)                                             | Modern web server with automatic HTTPS and simple configuration. Popular for its ease of use and zero-config SSL.                                   | Automatic HTTPS, HTTP/3 support, plugin system, JSON/Caddyfile config, built-in file server                 | Small to medium applications, rapid prototyping, development         |
| [**Traefik**](https://traefik.io/)                                                | Cloud-native reverse proxy with automatic service discovery. Integrates seamlessly with Docker, Kubernetes, and service mesh.                       | Automatic service discovery, Let's Encrypt integration, metrics/tracing, middleware system                  | Containerized applications, microservices, Kubernetes                |
| [**Envoy**](https://www.envoyproxy.io/)                                           | High-performance C++ proxy designed for cloud-native applications. Foundation of Istio service mesh.                                                | HTTP/2 & gRPC support, advanced observability, rate limiting, circuit breaking, WebAssembly extensions      | Service mesh, cloud-native apps, Kubernetes                          |
| [**Kong**](https://konghq.com/)                                                   | API gateway built on Nginx with extensive plugin ecosystem. Used by Samsung, Yahoo, and Expedia.                                                    | Plugin architecture, developer portal, analytics, OAuth/JWT support, rate limiting                          | API management, microservices gateway, enterprise APIs               |
| [**F5 BIG-IP**](https://www.f5.com/products/big-ip)                               | Enterprise-grade application delivery controller with advanced security and performance features.                                                   | Advanced security (WAF, DDoS protection), application acceleration, global load balancing, iRules scripting | Enterprise applications, high-security environments, complex routing |
| [**Cloudflare**](https://www.cloudflare.com/)                                     | Global CDN and reverse proxy service with edge computing capabilities.                                                                              | Global edge network, DDoS protection, serverless computing, image optimization, security features           | Global applications, DDoS protection, edge computing                 |
| [**AWS Application Load Balancer**](https://aws.amazon.com/elasticloadbalancing/) | Managed layer 7 load balancer with tight AWS integration and automatic scaling.                                                                     | AWS integration, auto-scaling, SSL termination, content-based routing, health checks                        | AWS-hosted applications, auto-scaling workloads                      |

<BackToTop />

## Implementation Examples

### Node.js Express with HTTP Proxy Middleware

```javascript
// server.js - Simple reverse proxy with Express
const express = require("express");
const { createProxyMiddleware } = require("http-proxy-middleware");
const rateLimit = require("express-rate-limit");
const helmet = require("helmet");

const app = express();

// Security middleware
app.use(
  helmet({
    hsts: {
      maxAge: 31536000,
      includeSubDomains: true,
      preload: true,
    },
  })
);

// Rate limiting
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // limit each IP to 100 requests per windowMs
  message: "Too many requests from this IP, please try again later.",
  standardHeaders: true,
  legacyHeaders: false,
});

app.use(limiter);

// Health check endpoint
app.get("/health", (req, res) => {
  res.status(200).json({
    status: "healthy",
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
  });
});

// Backend servers
const backends = [
  "http://backend1:3000",
  "http://backend2:3000",
  "http://backend3:3000",
];

let currentBackend = 0;

// Simple round-robin load balancer
const getNextBackend = () => {
  const backend = backends[currentBackend];
  currentBackend = (currentBackend + 1) % backends.length;
  return backend;
};

// API proxy with load balancing
app.use(
  "/api",
  createProxyMiddleware({
    target: getNextBackend(),
    changeOrigin: true,
    pathRewrite: {
      "^/api": "", // remove /api prefix
    },
    onProxyReq: (proxyReq, req, res) => {
      // Add custom headers
      proxyReq.setHeader("X-Forwarded-Host", req.get("Host"));
      proxyReq.setHeader("X-Forwarded-Proto", req.protocol);
      proxyReq.setHeader("X-Real-IP", req.ip);

      console.log(
        `Proxying ${req.method} ${req.url} to ${proxyReq.getHeader("host")}`
      );
    },
    onProxyRes: (proxyRes, req, res) => {
      // Add security headers
      proxyRes.headers["X-Content-Type-Options"] = "nosniff";
      proxyRes.headers["X-Frame-Options"] = "DENY";

      console.log(`Response ${proxyRes.statusCode} from ${req.url}`);
    },
    onError: (err, req, res) => {
      console.error("Proxy error:", err);
      res.status(500).json({ error: "Proxy error occurred" });
    },
  })
);

// Static file proxy
app.use(
  "/static",
  createProxyMiddleware({
    target: "http://cdn-server:8080",
    changeOrigin: true,
    onProxyRes: (proxyRes, req, res) => {
      // Cache static files for 1 hour
      proxyRes.headers["Cache-Control"] = "public, max-age=3600";
    },
  })
);

// WebSocket proxy
app.use(
  "/ws",
  createProxyMiddleware({
    target: "http://websocket-server:8080",
    ws: true,
    changeOrigin: true,
  })
);

// Default proxy for web application
app.use(
  "/",
  createProxyMiddleware({
    target: "http://web-server:8080",
    changeOrigin: true,
    onProxyReq: (proxyReq, req, res) => {
      proxyReq.setHeader("X-Forwarded-For", req.ip);
    },
  })
);

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Reverse proxy server running on port ${PORT}`);
});
```

<BackToTop />

### Python Flask Reverse Proxy

```python
# proxy_server.py
from flask import Flask, request, Response
import requests
import random
import time
import logging
from functools import wraps
from collections import defaultdict

app = Flask(__name__)

# Configuration
BACKEND_SERVERS = [
    'http://backend1:5000',
    'http://backend2:5000',
    'http://backend3:5000'
]

RATE_LIMIT = 100  # requests per minute
rate_limit_storage = defaultdict(list)

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HealthChecker:
    def __init__(self, servers):
        self.servers = servers
        self.healthy_servers = set(servers)

    def check_health(self, server):
        try:
            response = requests.get(f"{server}/health", timeout=5)
            return response.status_code == 200
        except requests.RequestException:
            return False

    def get_healthy_servers(self):
        current_time = time.time()
        for server in self.servers:
            if self.check_health(server):
                self.healthy_servers.add(server)
            else:
                self.healthy_servers.discard(server)
                logger.warning(f"Server {server} is unhealthy")

        return list(self.healthy_servers) if self.healthy_servers else self.servers

health_checker = HealthChecker(BACKEND_SERVERS)

def rate_limit_check(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        client_ip = request.remote_addr
        current_time = time.time()

        # Clean old entries
        rate_limit_storage[client_ip] = [
            timestamp for timestamp in rate_limit_storage[client_ip]
            if current_time - timestamp < 60  # Last minute
        ]

        # Check rate limit
        if len(rate_limit_storage[client_ip]) >= RATE_LIMIT:
            return Response(
                'Rate limit exceeded',
                status=429,
                headers={'Retry-After': '60'}
            )

        rate_limit_storage[client_ip].append(current_time)
        return f(*args, **kwargs)

    return decorated_function

def get_backend_server():
    """Simple round-robin load balancing with health checks"""
    healthy_servers = health_checker.get_healthy_servers()
    if not healthy_servers:
        raise Exception("No healthy backend servers available")

    return random.choice(healthy_servers)

@app.route('/health')
def health_check():
    return {
        'status': 'healthy',
        'timestamp': time.time(),
        'backend_servers': len(health_checker.get_healthy_servers())
    }

@app.route('/', defaults={'path': ''}, methods=['GET', 'POST', 'PUT', 'DELETE', 'PATCH'])
@app.route('/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE', 'PATCH'])
@rate_limit_check
def proxy(path):
    try:
        # Get healthy backend server
        backend_server = get_backend_server()

        # Prepare headers
        headers = dict(request.headers)
        headers['X-Forwarded-For'] = request.remote_addr
        headers['X-Forwarded-Proto'] = request.scheme
        headers['X-Forwarded-Host'] = request.headers.get('Host', '')

        # Remove hop-by-hop headers
        hop_by_hop_headers = [
            'connection', 'keep-alive', 'proxy-authenticate',
            'proxy-authorization', 'te', 'trailers', 'upgrade'
        ]

        for header in hop_by_hop_headers:
            headers.pop(header, None)

        # Make request to backend
        url = f"{backend_server}/{path}"
        if request.query_string:
            url += f"?{request.query_string.decode()}"

        logger.info(f"Proxying {request.method} {url}")

        response = requests.request(
            method=request.method,
            url=url,
            headers=headers,
            data=request.get_data(),
            cookies=request.cookies,
            allow_redirects=False,
            timeout=30
        )

        # Prepare response
        excluded_headers = [
            'content-encoding', 'content-length', 'transfer-encoding', 'connection'
        ]

        response_headers = [
            (name, value) for name, value in response.headers.items()
            if name.lower() not in excluded_headers
        ]

        # Add security headers
        response_headers.extend([
            ('X-Content-Type-Options', 'nosniff'),
            ('X-Frame-Options', 'DENY'),
            ('X-XSS-Protection', '1; mode=block'),
        ])

        return Response(
            response.content,
            status=response.status_code,
            headers=response_headers
        )

    except requests.RequestException as e:
        logger.error(f"Proxy error: {e}")
        return Response(
            'Backend server error',
            status=502
        )
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return Response(
            'Internal proxy error',
            status=500
        )

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=False)
```

<BackToTop />

### Kubernetes Ingress Controller Example

```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  namespace: production
  annotations:
    # Nginx ingress controller
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/rewrite-target: /

    # SSL configuration
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"

    # Rate limiting
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"

    # Load balancing
    nginx.ingress.kubernetes.io/load-balance: "least_conn"

    # CORS
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "https://app.example.com"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, PUT, DELETE, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization"

    # Security headers
    nginx.ingress.kubernetes.io/configuration-snippet: |
      add_header X-Frame-Options DENY;
      add_header X-Content-Type-Options nosniff;
      add_header X-XSS-Protection "1; mode=block";
      add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

    # Custom error pages
    nginx.ingress.kubernetes.io/custom-http-errors: "404,503"
    nginx.ingress.kubernetes.io/default-backend: error-pages

spec:
  tls:
    - hosts:
        - app.example.com
        - api.example.com
      secretName: example-tls

  rules:
    - host: app.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: web-app-service
                port:
                  number: 80

          - path: /static
            pathType: Prefix
            backend:
              service:
                name: static-service
                port:
                  number: 80

    - host: api.example.com
      http:
        paths:
          - path: /v1
            pathType: Prefix
            backend:
              service:
                name: api-v1-service
                port:
                  number: 3000

          - path: /v2
            pathType: Prefix
            backend:
              service:
                name: api-v2-service
                port:
                  number: 3000

---
# Service definitions
apiVersion: v1
kind: Service
metadata:
  name: web-app-service
  namespace: production
spec:
  selector:
    app: web-app
  ports:
    - port: 80
      targetPort: 8080
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: api-v1-service
  namespace: production
spec:
  selector:
    app: api
    version: v1
  ports:
    - port: 3000
      targetPort: 3000
  type: ClusterIP
```

<BackToTop />

## Best Practices

### Configuration Management

1. **Infrastructure as Code**:

```yaml
# terraform/reverse-proxy.tf
resource "aws_lb" "main" {
name               = "main-alb"
internal           = false
load_balancer_type = "application"
security_groups    = [aws_security_group.alb.id]
subnets            = var.public_subnet_ids

enable_deletion_protection = true

tags = {
Environment = var.environment
Project     = var.project_name
}
}

resource "aws_lb_target_group" "app" {
name     = "app-tg"
port     = 80
protocol = "HTTP"
vpc_id   = var.vpc_id

health_check {
enabled             = true
healthy_threshold   = 2
interval            = 30
matcher             = "200"
path                = "/health"
port                = "traffic-port"
protocol            = "HTTP"
timeout             = 5
unhealthy_threshold = 2
}

tags = {
Environment = var.environment
}
}

resource "aws_lb_listener" "app" {
load_balancer_arn = aws_lb.main.arn
port              = "443"
protocol          = "HTTPS"
ssl_policy        = "ELBSecurityPolicy-TLS-1-2-2017-01"
certificate_arn   = var.ssl_certificate_arn

default_action {
type             = "forward"
target_group_arn = aws_lb_target_group.app.arn
}
}
```

2. **Configuration Testing**:

```bash
#!/bin/bash
# test-nginx-config.sh

# Test Nginx configuration
nginx -t

# Test with specific config file
nginx -t -c /etc/nginx/test.conf

# Reload configuration gracefully
nginx -s reload

# Test proxy functionality
curl -H "Host: api.example.com" http://localhost/health
curl -H "X-Forwarded-For: 192.168.1.100" http://localhost/api/test
```

<BackToTop />

### Security Hardening

```nginx
# Security-focused Nginx configuration
server {
    listen 443 ssl http2;
    server_name secure-app.example.com;

    # SSL Configuration
    ssl_certificate /etc/ssl/certs/secure-app.crt;
    ssl_certificate_key /etc/ssl/private/secure-app.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # Security headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'" always;

    # Hide server information
    server_tokens off;
    add_header X-Served-By "SecureProxy" always;

    # Rate limiting zones
    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=general:10m rate=100r/s;

    # Request size limits
    client_max_body_size 10M;
    client_body_buffer_size 128k;
    client_header_buffer_size 3m;
    large_client_header_buffers 4 256k;

    # Login endpoint with strict rate limiting
    location /login {
        limit_req zone=login burst=5 nodelay;
        proxy_pass http://auth_backend;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # API endpoints with moderate rate limiting
    location /api/ {
        limit_req zone=api burst=20 nodelay;

        # Additional API security
        if ($request_method !~ ^(GET|POST|PUT|DELETE|PATCH|OPTIONS)$ ) {
            return 405;
        }

        proxy_pass http://api_backend;
        proxy_set_header Authorization $http_authorization;
        proxy_hide_header X-Powered-By;
    }

    # Block common attack patterns
    location ~* (\.php|\.asp|\.aspx|\.jsp)$ {
        return 444;
    }

    # Block access to sensitive files
    location ~* \.(htaccess|htpasswd|ini|log|sh|sql|conf)$ {
        deny all;
        return 444;
    }
}
```

<BackToTop />

### Performance Optimization

```nginx
# Performance-optimized Nginx configuration
http {
    # Basic optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 30;
    keepalive_requests 1000;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Brotli compression (if module available)
    brotli on;
    brotli_comp_level 6;
    brotli_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # Proxy caching
    proxy_cache_path /var/cache/nginx/proxy levels=1:2 keys_zone=proxy_cache:10m max_size=1g inactive=1h use_temp_path=off;

    upstream backend_pool {
        least_conn;
        server backend1:8080 max_fails=3 fail_timeout=30s;
        server backend2:8080 max_fails=3 fail_timeout=30s;
        server backend3:8080 max_fails=3 fail_timeout=30s;

        # Connection pooling
        keepalive 32;
        keepalive_requests 1000;
        keepalive_timeout 60s;
    }

    server {
        listen 443 ssl http2;

        # HTTP/2 optimizations
        http2_max_field_size 16k;
        http2_max_header_size 32k;

        # Static content with aggressive caching
        location ~* \.(jpg|jpeg|png|gif|ico|css|js|woff2?)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header Vary "Accept-Encoding";

            # Serve from cache if available
            proxy_cache proxy_cache;
            proxy_cache_valid 200 1h;
            proxy_cache_key $uri$is_args$args;

            proxy_pass http://backend_pool;
        }

        # Dynamic content with smart caching
        location / {
            proxy_cache proxy_cache;
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_key $scheme$request_method$host$request_uri;
            proxy_cache_bypass $http_pragma $http_authorization;

            # Add cache status header
            add_header X-Cache-Status $upstream_cache_status;

            proxy_pass http://backend_pool;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Buffering optimizations
            proxy_buffering on;
            proxy_buffer_size 128k;
            proxy_buffers 4 256k;
            proxy_busy_buffers_size 256k;
        }
    }
}
```

<BackToTop />

## Monitoring and Troubleshooting

### Monitoring Configuration

```yaml
# prometheus/proxy-monitoring.yml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: nginx-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: nginx-exporter
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics

---
# Grafana dashboard configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: proxy-dashboard
  namespace: monitoring
data:
  dashboard.json: |
    {
      "dashboard": {
        "title": "Reverse Proxy Monitoring",
        "panels": [
          {
            "title": "Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(nginx_http_requests_total[5m])",
                "legendFormat": "{{server}}"
              }
            ]
          },
          {
            "title": "Response Time",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, rate(nginx_http_request_duration_seconds_bucket[5m]))",
                "legendFormat": "95th percentile"
              }
            ]
          },
          {
            "title": "Error Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(nginx_http_requests_total{status=~\"5..\"}[5m])",
                "legendFormat": "5xx errors"
              }
            ]
          }
        ]
      }
    }
```

<BackToTop />

### Logging and Alerting

```nginx
# Advanced logging configuration
http {
    log_format detailed '$remote_addr - $remote_user [$time_local] '
                       '"$request" $status $body_bytes_sent '
                       '"$http_referer" "$http_user_agent" '
                       'rt=$request_time uct="$upstream_connect_time" '
                       'uht="$upstream_header_time" urt="$upstream_response_time" '
                       'cs=$upstream_cache_status';

    # Separate log files for different types
    access_log /var/log/nginx/access.log detailed;
    error_log /var/log/nginx/error.log warn;

    # API-specific logging
    map $request_uri $api_log {
        ~^/api/ 1;
        default 0;
    }

    server {
        # API request logging
        access_log /var/log/nginx/api_access.log detailed if=$api_log;

        # Error page logging
        error_page 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
            access_log /var/log/nginx/errors.log;
        }
    }
}
```

### Health Check Scripts

```bash
#!/bin/bash
# health-check.sh

PROXY_URL="http://localhost"
BACKEND_URLS=("http://backend1:8080" "http://backend2:8080" "http://backend3:8080")
SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."

check_proxy_health() {
    response=$(curl -s -o /dev/null -w "%{http_code}" "$PROXY_URL/health")
    if [ "$response" != "200" ]; then
        echo "Proxy health check failed: HTTP $response"
        send_alert "Proxy server health check failed"
        return 1
    fi
    return 0
}

check_backend_health() {
    for backend in "${BACKEND_URLS[@]}"; do
        response=$(curl -s -o /dev/null -w "%{http_code}" "$backend/health")
        if [ "$response" != "200" ]; then
            echo "Backend $backend health check failed: HTTP $response"
            send_alert "Backend server $backend is down"
        fi
    done
}

check_ssl_certificate() {
    expiry_date=$(echo | openssl s_client -servername example.com -connect example.com:443 2>/dev/null | openssl x509 -noout -dates | grep notAfter | cut -d= -f2)
    expiry_timestamp=$(date -d "$expiry_date" +%s)
    current_timestamp=$(date +%s)
    days_until_expiry=$(( (expiry_timestamp - current_timestamp) / 86400 ))

    if [ $days_until_expiry -lt 30 ]; then
        send_alert "SSL certificate expires in $days_until_expiry days"
    fi
}

send_alert() {
    message="$1"
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"🚨 Alert: $message\"}" \
        "$SLACK_WEBHOOK_URL"
}

# Run checks
check_proxy_health
check_backend_health
check_ssl_certificate
```

<BackToTop />
